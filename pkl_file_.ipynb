{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pkl file .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srikanth9142/ML-works/blob/master/pkl_file_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIsVIWzSjzSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####This notebook is for running after saving the data in pickle files "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmQgDwb4kHl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-yHjd3GkLLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCzDmZdRknyS",
        "colab_type": "text"
      },
      "source": [
        "##Mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxRQJSOukQ_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0iK2CHkksox",
        "colab_type": "text"
      },
      "source": [
        "##Unzipping folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnfR8tDkbXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q \"/content/drive/My Drive/dataset_updated_20.zip\"\n",
        "%ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO9kbv56ky1Q",
        "colab_type": "text"
      },
      "source": [
        "## Installed && imported modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUqxCf4wkhdY",
        "colab_type": "code",
        "outputId": "f5b6fa6f-f611-47a8-c79d-421010d2e0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "pip install python_speech_features\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5889 sha256=715e75ff54b6dd08574bb638e0f17e10fdec5584a69962500d05ea3509ff96f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqH4IwAwlAFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from python_speech_features import mfcc,delta,logfbank \n",
        "from tqdm import tnrange\n",
        "import numpy\n",
        "import scipy.io.wavfile\n",
        "import numpy as np\n",
        "import wave\n",
        "import contextlib\n",
        "from scipy.fftpack import dct\n",
        "import scipy.io.wavfile as wav\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKJAZGtsoILJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRhgOTFTlkGH",
        "colab_type": "text"
      },
      "source": [
        "##Loading the pickle files into arrays for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXqGYthElPJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##add pickle file path(x-train)\n",
        "with(\"#\",as \"rb\")as f:\n",
        "  x_train = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "othVEl8HnAHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##add pickle file path(x-test)\n",
        "with(\"#\",as \"rb\")as f:\n",
        "  x_test = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqYFUYFTnbaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##add pickle file path(y-train)\n",
        "with(\"#\",as \"rb\")as f:\n",
        "  y_train= pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iFImpYynnaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##add pickle file path(y_test)\n",
        "with(\"#\",as \"rb\")as f:\n",
        "  y_test= pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO-QfEVGplj3",
        "colab_type": "text"
      },
      "source": [
        "##Imports needed for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W72c4QM_n-QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization,AveragePooling2D\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D,Dropout,Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZr6UVBTqIiu",
        "colab_type": "text"
      },
      "source": [
        "##Function for Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mft5Q6wqHnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create model function \n",
        "def create_model():\n",
        "  base_model=applications.resnet50.ResNet50(weights=None,include_top=False,input_shape = (40,40,1))\n",
        "  x = base_model.output\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = AveragePooling2D(pool_size=2)(x)\n",
        "  z1 = Flatten()(x)\n",
        "  outputs = Dense(11,activation='softmax',kernel_initializer='he_normal')(z1)\n",
        "  rnet=Model(inputs=base_model.input,outputs=outputs)\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(1,(3,3),padding='same',activation = 'relu',input_shape = (398,40,1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "  model.add(Convolution2D(1, 2, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(rnet)\n",
        "  adam=Adam(lr=0.0001)\n",
        "  model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIgBf2m1qzjn",
        "colab_type": "text"
      },
      "source": [
        "##Functions for prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTdNKeMUqyzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(targ):\n",
        "    accents = ['bengali','dogri','gujarathi','hindi','malayalam','manipuri','marathi','odisha','tamil','telugu','urdu']\n",
        "    np.set_printoptions(formatter={'float_kind':'{:.1f}'.format})\n",
        "    #np.set_printoptions(formatter={'float_kind':'{:.1f}'.format})\n",
        "    l=[]\n",
        "    out_len = len(targ)\n",
        "    in_len = len(targ[0])\n",
        "    for i in range(in_len):\n",
        "        sumi = 0\n",
        "        for j in range(out_len):\n",
        "            sumi+=targ[j][i]\n",
        "        l.append(sumi)\n",
        "    print(l)\n",
        "    maximum = -1\n",
        "    max_ind = -1\n",
        "    for i in range(len(l)):\n",
        "        if(l[i] > maximum):\n",
        "            maximum = l[i]\n",
        "            max_ind = i+1\n",
        "    # print(maximum, max_ind)\n",
        "    print(\"Accent: \",accents[max_ind-1])\n",
        "    for i in l:\n",
        "        if i!=0:\n",
        "            per = (i/float(out_len))*100\n",
        "            if(per>1):\n",
        "                print(\"{1:.2f}% -> {0}\".format(accents[l.index(i)],per))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8FeeEnMrGKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## This is for testing \n",
        "def Pre_final_data(folder,files):\n",
        "    index=0\n",
        "    \n",
        "    mfcc=[]\n",
        "    target=[]\n",
        "    mfcc_len=length_audio(folder,files)\n",
        "    count=0\n",
        "    for z in range(0,mfcc_len,2):\n",
        "      count=count+1\n",
        "    data_dic = np.zeros((count,398,40))\n",
        "    for i in range(0,mfcc_len,2):\n",
        "        \n",
        "        mfcc = create_mfcc(folder,files,i)\n",
        "        for j in range(len(mfcc)):\n",
        "              for k in range(len(mfcc[j])):\n",
        "                data_dic[index][j][k] = mfcc[j][k]\n",
        "        index += 1\n",
        "        #target.append(mfcc)\n",
        "      #target=np.asarray()\n",
        "    \n",
        "    data_dic_reshaped = data_dic.reshape(data_dic.shape[0],398,40,1)\n",
        "    model = create_model()\n",
        "    #model.load_weights('drive/My Drive/Language3.h5')\n",
        "    model.load_weights('drive/My Drive/Language3.h5')\n",
        "    targ=model.predict(data_dic_reshaped)    \n",
        "    print(targ)\n",
        "    print(prediction(targ))\n",
        "    #print(data_dic_reshaped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v2Lw0rZlWEC",
        "colab_type": "text"
      },
      "source": [
        "##Functions need for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTbeKBDarqNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variables used in MFCC\n",
        "pre_emphasis = 0.97\n",
        "frame_size = 0.025\n",
        "frame_stride = 0.01\n",
        "NFFT = 512\n",
        "nfilt = 40\n",
        "num_ceps = 12\n",
        "cep_lifter =22"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNnCpyh-r3Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The below function is to find the length of the audio with given input foldername and filename\n",
        "def length_audio(folder_name,file_name):\n",
        "  file_path='/content/'+str(folder_name)+\"/\"+str(file_name)\n",
        "  sample_rate, signal = scipy.io.wavfile.read(file_path)\n",
        "  with contextlib.closing(wave.open(file_path,'r')) as f:\n",
        "      frames = f.getnframes()\n",
        "      rate = f.getframerate()\n",
        "      duration = frames / float(rate)\n",
        "  return int(duration)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvoVYmiMsDgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mfcc(folder_name,file_name,start_point):\n",
        "    file_path ='/content/'+str(folder_name)+\"/\"+str(file_name)\n",
        "    sample_rate, signal = scipy.io.wavfile.read(file_path)\n",
        "    signal = signal[start_point:int(start_point+2 * sample_rate)]   #framing to 2 seconds\n",
        "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1]) #pre-emphasis\n",
        "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
        "    signal_length = len(emphasized_signal)\n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "    num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = numpy.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
        "    indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
        "    #After slicing the signal into frames, we apply a window function such as the Hamming window\n",
        "    frames *= numpy.hamming(frame_length)  #hamming window\n",
        "    mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
        "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
        "    low_freq_mel = 0\n",
        "    high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
        "    mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
        "    bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])   # left\n",
        "        f_m = int(bin[m])             # center\n",
        "        f_m_plus = int(bin[m + 1])    # right\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
        "\n",
        "    filter_banks = numpy.dot(pow_frames, fbank.T)\n",
        "    filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
        "    filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
        "    mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
        "    (nframes, ncoeff) = mfcc.shape\n",
        "    n = numpy.arange(ncoeff)\n",
        "    lift = 1 + (cep_lifter / 2) * numpy.sin(numpy.pi * n / cep_lifter)\n",
        "    mfcc *= lift  #*\n",
        "    \n",
        "    filter_banks -= (numpy.mean(filter_banks, axis=0) + 1e-8)\n",
        "    mfcc -= (numpy.mean(mfcc, axis=0) + 1e-8)\n",
        "    \n",
        "    return filter_banks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptKHXxcZswMY",
        "colab_type": "text"
      },
      "source": [
        "##Fit the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWAA5Sn_sVtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "model.fit(x_train,y_train,epochs = 25,batch_size=64)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}